import streamlit as st
import data_loader
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv

# --- Config ---
st.set_page_config(page_title="ç¤¾ç§‘ AI åŠ©æ•™", page_icon="ğŸ“", layout="centered")
load_dotenv()

# --- API Setup ---
# Try to get API Key from environment (System or .env)
api_key = os.getenv("GEMINI_API_KEY") 
if not api_key:
    # Fallback: User input in sidebar if not Environment
    with st.sidebar:
        api_key = st.text_input("Gemini API Key", type="password")
        if not api_key:
            st.warning("è«‹è¼¸å…¥æ‚¨çš„ Gemini API Key ä»¥ç¹¼çºŒ")
            st.stop()

# --- Model Setup ---
def get_available_model():
    """Finds the best available model from the API."""
    try:
        # List all models that support generation
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                available_models.append(m.name)
        
        # Priority list
        priorities = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']
        
        for p in priorities:
            if p in available_models:
                return p
        
        # Fallback to the first available if none of the above match
        if available_models:
            return available_models[0]
            
        return "models/gemini-pro" # Ultimate fallback
    except Exception as e:
        # If list_models fails (e.g. old lib), fallback to simple string
        return "gemini-pro"

# Configure Model
genai.configure(api_key=api_key)

# Select Model
model_name = get_available_model()
# st.toast(f"Using AI Model: {model_name}") # Optional: Notify user
model = genai.GenerativeModel(model_name)


# --- Session State Management ---
if "current_topic" not in st.session_state:
    st.session_state.current_topic = None
if "quiz_data" not in st.session_state:
    st.session_state.quiz_data = None
if "user_answers" not in st.session_state:
    st.session_state.user_answers = {}
if "graded" not in st.session_state:
    st.session_state.graded = False

# --- Helper Functions ---
def generate_quiz(topic_text):
    """Generates a quiz using Gemini in JSON format."""
    prompt = f"""
    You are a professional Sociology Tutor. 
    Based on the following course material, generate a quiz in **Traditional Chinese (ç¹é«”ä¸­æ–‡)**.
    
    Content:
    {topic_text[:20000]}  # Limit char count to safe range
    
    Requirements:
    1. 3 Multiple Choice Questions (MCQ) with 4 options.
    2. 1 Short Answer Question (SA).
    3. **ALL Content must be in Traditional Chinese (TW).**
    
    Output STRICT JSON format:
    {{
        "mcq": [
            {{
                "q": "é¡Œç›®å…§å®¹...",
                "options": ["A) é¸é … 1", "B) é¸é … 2", "C) ...", "D) ..."],
                "correct_index": 0  (0 for A, 1 for B, etc.)
            }}
        ],
        "sa": [
            {{
                "q": "é¡Œç›®å…§å®¹...",
                "reference_answer": "åƒè€ƒç­”æ¡ˆé‡é»..."
            }}
        ]
    }}
    """
    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(response.text)
    except Exception as e:
        st.error(f"ç”Ÿæˆæ¸¬é©—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def grade_sa(question, student_answer, reference):
    """Uses AI to grade the short answer."""
    prompt = f"""
    You are a Teacher grading a student's answer.
    
    Question: {question}
    Reference Answer (from material): {reference}
    Student Answer: {student_answer}
    
    Task:
    Provide a concise evaluation (Pass/Fail) and constructive feedback/correction. 
    **Reply in Traditional Chinese (ç¹é«”ä¸­æ–‡).**
    Focus on sociology concepts.
    """
    response = model.generate_content(prompt)
    return response.text

# --- UI Layout ---
st.title("ğŸ“ Exam_Tutor AI (ä¸­æ–‡ç‰ˆ)")
st.caption("æ‚¨çš„å€‹äººåŒ–ç¤¾æœƒå­¸ AI åŠ©æ•™")

# 1. Sidebar: Select Topic
materials = data_loader.load_materials()
if not materials:
    st.error("åœ¨ 'materials/' è³‡æ–™å¤¾ä¸­æ‰¾ä¸åˆ°è¬›ç¾©æª”æ¡ˆ")
    st.stop()

topic_list = list(materials.keys())
selected_topic = st.sidebar.selectbox("ğŸ“š é¸æ“‡å–®å…ƒ/é€±æ¬¡", topic_list)

# Reset state if topic changes
if selected_topic != st.session_state.current_topic:
    st.session_state.current_topic = selected_topic
    st.session_state.quiz_data = None
    st.session_state.user_answers = {}
    st.session_state.graded = False

# 2. Main Area: Generate Button
if st.session_state.quiz_data is None:
    st.info(f"æº–å‚™ç·´ç¿’å–®å…ƒ: **{selected_topic}**")
    if st.button("ğŸš€ é–‹å§‹æ¸¬é©— (Start Quiz)", type="primary"):
        with st.spinner("ğŸ¤– AI æ­£åœ¨é–±è®€è¬›ç¾©ä¸¦å‡ºé¡Œä¸­..."):
            text_content = materials[selected_topic]
            quiz = generate_quiz(text_content)
            if quiz:
                st.session_state.quiz_data = quiz
                st.rerun()

# 3. Quiz Area
if st.session_state.quiz_data:
    quiz = st.session_state.quiz_data
    
    with st.form("quiz_form"):
        st.subheader("ç¬¬ä¸€éƒ¨åˆ†: é¸æ“‡é¡Œ (MCQ)")
        
        # MCQs
        mcq_answers = {}
        for i, q in enumerate(quiz["mcq"]):
            st.markdown(f"**{i+1}. {q['q']}**")
            # Streamlit radio returns the string value of the option
            mcq_answers[i] = st.radio(f"è«‹é¸æ“‡ç¬¬ {i+1} é¡Œç­”æ¡ˆ", q['options'], key=f"mcq_{i}", label_visibility="collapsed")
            st.markdown("---")
            
        st.subheader("ç¬¬äºŒéƒ¨åˆ†: ç°¡ç­”é¡Œ (Short Answer)")
        
        # SAs
        sa_answers = {}
        for i, q in enumerate(quiz["sa"]):
            st.markdown(f"**{i+1}. {q['q']}**")
            sa_answers[i] = st.text_area("æ‚¨çš„å›ç­”:", key=f"sa_{i}")

        submitted = st.form_submit_button("ğŸ“ æäº¤ä¸¦è©•åˆ† (Submit)")
        
        if submitted:
            st.session_state.graded = True
            st.session_state.user_answers = {"mcq": mcq_answers, "sa": sa_answers}

# 4. Grading Results
if st.session_state.graded and st.session_state.quiz_data:
    st.divider()
    st.header("ğŸ“Š æˆç¸¾èˆ‡å›é¥‹")
    
    quiz = st.session_state.quiz_data
    u_ans = st.session_state.user_answers
    
    # Grade MCQs
    score = 0
    total = len(quiz["mcq"])
    
    for i, q in enumerate(quiz["mcq"]):
        user_choice = u_ans["mcq"][i] # String "A) ..."
        correct_choice = q['options'][q['correct_index']]
        
        if user_choice == correct_choice:
            score += 1
            st.success(f"ç¬¬ {i+1} é¡Œ: ç­”å°äº†ï¼ âœ…")
        else:
            st.error(f"ç¬¬ {i+1} é¡Œ: éŒ¯èª¤ âŒ")
            st.markdown(f"- **æ‚¨çš„ç­”æ¡ˆ**: {user_choice}")
            st.markdown(f"- **æ­£ç¢ºç­”æ¡ˆ**: {correct_choice}")
            
    st.metric("é¸æ“‡é¡Œå¾—åˆ†", f"{score}/{total}")
    
    # Grade SA
    st.subheader("ç°¡ç­”é¡Œ AI å›é¥‹")
    for i, q in enumerate(quiz["sa"]):
        user_text = u_ans["sa"][i]
        if not user_text.strip():
            st.warning("æœªå¡«å¯«ç­”æ¡ˆ")
            continue
            
        with st.spinner("AI æ­£åœ¨æ‰¹æ”¹æ‚¨çš„ç°¡ç­”é¡Œ..."):
            feedback = grade_sa(q['q'], user_text, q['reference_answer'])
            
        st.info(f"**é¡Œç›®**: {q['q']}")
        st.markdown(f"**AI è©•èª**: \n{feedback}")
        with st.expander("æŸ¥çœ‹è¬›ç¾©åƒè€ƒé‡é»"):
            st.markdown(q['reference_answer'])
            
    if st.button("ğŸ”„ ç·´ç¿’å…¶ä»–å–®å…ƒ"):
        st.session_state.quiz_data = None
        st.session_state.graded = False
        st.rerun()
